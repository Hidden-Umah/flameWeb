# Minimal NLP (from Scratch)

🚀 An educational project to learn and build **Natural Language Processing (NLP)** models from scratch using **Python + NumPy only** (no high-level ML libraries).  
The goal is to understand the **core building blocks** of NLP without relying on frameworks like GPT, BERT, or TensorFlow.  

---

## 📌 Project Overview
This project is part of my journey to learn **AI and NLP fundamentals** by implementing everything myself.  
We’ll start small (tokenization, vocabulary building, encoding) and progress toward simple models (bag-of-words, embeddings, RNNs).  

---

## ✨ Features (Planned / In Progress)
- ✅ Basic text cleaning and tokenization  
- ✅ Vocabulary building & word-to-index mapping  
- ⏳ Bag-of-Words representation  
- ⏳ TF-IDF implementation  
- ⏳ Word embeddings (from scratch)  
- ⏳ Simple RNN for text classification  

---

## 📂 Project Structure

minimal-nlp/
│── data/ # Sample text data
│── src/ # Source code (tokenizers, models, utils)
│── notebooks/ # Jupyter notebooks (experiments, demos)
│── tests/ # Unit tests
│── README.md # Project documentation
---

## 🛠️ Tech Stack
- **Python 3.10+**
- **NumPy**
- (Optional later: Matplotlib for visualization)

---

### 🚀 Getting Started
Clone the repo:
```bash
git clone https://github.com/Hidden-Umah/Legend-ai-lab.git
cd Legend-ai-lab

Install dependencies:

pip install -r requirements.txt

Run a simple tokenizer demo:

python src/tokenizer.py

📅 Roadmap

    Week 1 → Tokenization & Vocabulary

    Week 2 → Bag-of-Words & TF-IDF

    Week 3 → Word Embeddings

    Week 4 → Basic RNN for text classification

🤝 Contributing

This is mainly a learning project, but feedback and suggestions are welcome!
📖 License

MIT License — free to use, learn, and share.


---

